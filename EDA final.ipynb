{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opinion mining from the dataset of Amazon product reviews\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package product_reviews_1 to\n",
      "[nltk_data]     /Users/andrejwork/nltk_data...\n",
      "[nltk_data]   Package product_reviews_1 is already up-to-date!\n",
      "[nltk_data] Downloading package product_reviews_2 to\n",
      "[nltk_data]     /Users/andrejwork/nltk_data...\n",
      "[nltk_data]   Package product_reviews_2 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import product_reviews_1, product_reviews_2\n",
    "from textblob import TextBlob # for noun phrase extraction\n",
    "from apyori import apriori # For the Apriori algorithm\n",
    "from numpy import sign\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import string\n",
    "import time\n",
    "import itertools # For feature prunning\n",
    "import operator\n",
    "\n",
    "nltk.download('product_reviews_1')\n",
    "nltk.download('product_reviews_2')\n",
    "\n",
    "# print(product_reviews_1.fileids())\n",
    "# print(product_reviews_2.fileids())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storing internal state of the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PSent:\n",
    "    def __init__(self, s, f):\n",
    "        self.raw = s # Sentence in raw format\n",
    "        self.pp = [] # Sentence after preprocessing\n",
    "        self.ft = {} # Features / polarity based on model\n",
    "        self.op = [] # Opinion words\n",
    "        self.test = f # Test features labelled by human\n",
    "        self.eval = {} # Evaluation score\n",
    "        \n",
    "    def sentiment(self):\n",
    "        # Detecting sentiment polarity in the sentences                 \n",
    "        if self.ft:\n",
    "            # print(\"\\n\"+str(s))\n",
    "            p = TextBlob(str(self)).sentiment.polarity\n",
    "            if( p > 0 ):\n",
    "                p = 1                \n",
    "            elif( p < 0 ):\n",
    "                p = -1\n",
    "            # In base model there is no distintion\n",
    "            # between different features within one\n",
    "            # sentence:\n",
    "            for f in self.ft.keys():\n",
    "                self.ft[f] = p\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return \"PSent\"\n",
    "    \n",
    "    def __str__(self):\n",
    "        return ' '.join(self.raw)\n",
    "        \n",
    "class PRev:\n",
    "    def __init__(self, r):\n",
    "        self.NltkReview = r\n",
    "        self.review = []        \n",
    "        self.eval = {} # Evaluation score\n",
    "        \n",
    "    def preprocess(self, \n",
    "                         spelling = False,\n",
    "                         stemming = False,\n",
    "                         chunking = True,\n",
    "                         lemmatization = True):\n",
    "        \n",
    "        es = nltk.stem.SnowballStemmer('english')\n",
    "        \n",
    "        self.review = []\n",
    "        \n",
    "        for rl in self.NltkReview.review_lines:\n",
    "            \n",
    "            ps = PSent(rl.sent, \n",
    "                       rl.features) # Human labelled features\n",
    "            \n",
    "            a = ' '.join(rl.sent)\n",
    "            a = TextBlob(a)\n",
    "\n",
    "            # 2. spelling correction \n",
    "            if(spelling):                    \n",
    "                a = a.correct() \n",
    "            \n",
    "            # 3. get all nouns\n",
    "            nouns = []\n",
    "            for pos in a.tags:\n",
    "                if (pos[1][:2] == 'NN' \n",
    "                   and len(pos[0])>=3):\n",
    "                    nouns.append(pos[0])\n",
    "\n",
    "            # 4. Chunking noun phrases\n",
    "            if(chunking):\n",
    "                nouns = a.noun_phrases + nouns\n",
    "                # nouns = get_noun_phrases(' '.join(rl.sent)) + nouns\n",
    "\n",
    "            # 5. Lemmatication            \n",
    "            if(lemmatization):\n",
    "                nouns = [n.lemmatize() for n in nouns]\n",
    "            \n",
    "            \n",
    "            # 5. Stemming the words in the noun phrases\n",
    "            if(stemming):      \n",
    "                nouns = [es.stem(n) for n in nouns]\n",
    "            \n",
    "            ps.pp=nouns\n",
    "            self.review.append(ps)\n",
    "                \n",
    "            \n",
    "    def sents(self):\n",
    "        return [s.pp for s in self.review]\n",
    "    \n",
    "    def sents_raw(self):\n",
    "        return [s.raw for s in self.review]\n",
    "    \n",
    "    def sents_str(self):\n",
    "        rs = \"\"\n",
    "        for s in self.review:\n",
    "            rs +=' '.join(s.pp)\n",
    "        return rs\n",
    "            \n",
    "    def sentiment(self):\n",
    "        # Detecting sentiment polarity in the sentences\n",
    "        # containing product features        \n",
    "        for s in self.review:               \n",
    "            s.sentiment()\n",
    "            \n",
    "    def features(self):\n",
    "        self.ft = []\n",
    "        for s in self.review:\n",
    "            self.ft.extend(s.ft.keys())\n",
    "        return list(set(self.ft))\n",
    "            \n",
    "            \n",
    "    def __str__(self):\n",
    "        # rstr = self.NltkReview.title\n",
    "        rstr = \"\"\n",
    "        for s in self.NltkReview.sents():\n",
    "            rstr += ' '.join(s)+'\\n'\n",
    "        return rstr\n",
    "\n",
    "    \n",
    "class PReviews:\n",
    "    \n",
    "    def __init__(self, corpus, name):  \n",
    "        self.name = name  \n",
    "        self.NltkCorpus = corpus.reviews(name)\n",
    "        self.eval = {} # Evaluation score\n",
    "        self.report = {}\n",
    "        self.test_report = {}\n",
    "        \n",
    "        self.revs = []\n",
    "        for r in self.NltkCorpus:\n",
    "            self.revs.append(PRev(r))\n",
    "            \n",
    "        # print(len(self.revs))\n",
    "        \n",
    "    def preprocess(self, \n",
    "                         spelling = False,\n",
    "                         stemming = False,\n",
    "                         chunking = True,\n",
    "                         lemmatization = True):\n",
    "        \n",
    "        start = time.time()\n",
    "\n",
    "        for r in self.revs:\n",
    "            r.preprocess(spelling = spelling,\n",
    "                         stemming = stemming,\n",
    "                         chunking = chunking,\n",
    "                         lemmatization=lemmatization)\n",
    "            \n",
    "        end = time.time()\n",
    "\n",
    "        print(\"Preprocessed {} reviews in {:.2f} seconds (spelling correction={}, stemming={})\"\n",
    "              .format(len(self.revs), end-start, spelling, stemming))\n",
    "        \n",
    "    def get_tfidf_top_features(self, \n",
    "                               documents, \n",
    "                               tfidf_max_df=0.90, \n",
    "                               tfidf_min_df=0.05, \n",
    "                               tfidf_max_df_ngram_range=(1,3),\n",
    "                               n_top=30):\n",
    "        # print(\"TFIDF {} {} {} {}\".format(tfidf_max_df, tfidf_min_df,tfidf_max_df_ngram_range, n_top))\n",
    "        tfidf_vectorizer = TfidfVectorizer(max_df=tfidf_max_df, \n",
    "                                           min_df=tfidf_min_df, \n",
    "                                           stop_words='english', \n",
    "                                           ngram_range=tfidf_max_df_ngram_range)\n",
    "        tfidf = tfidf_vectorizer.fit_transform(documents)\n",
    "        importance = np.argsort(np.asarray(tfidf.sum(axis=0)).ravel())[::-1]\n",
    "        tfidf_feature_names = np.array(tfidf_vectorizer.get_feature_names())\n",
    "        \n",
    "        # features_by_gram = defaultdict(list)\n",
    "        # for f, w in zip(tfidf_vectorizer.get_feature_names(), tfidf_vectorizer.idf_):\n",
    "        #    features_by_gram[len(f.split(' '))].append((f, w))\n",
    "\n",
    "        # print(tfidf_vectorizer.get_feature_names())\n",
    "\n",
    "        # for gram, features in features_by_gram.items():\n",
    "        #    top_features = sorted(features, key=lambda x: x[1], reverse=True)[:n_top]\n",
    "\n",
    "        #    top_features = [f[0] for f in top_features]\n",
    "        #    print('{}-gram top:{}'.format(gram, top_features))\n",
    "    \n",
    "        return tfidf_feature_names[importance[:n_top]]\n",
    "    \n",
    "    \n",
    "    def features(self,\n",
    "                 apr = True,\n",
    "                 prune = True,\n",
    "                 tfidf_max_df=0.90, \n",
    "                 tfidf_min_df=0.05, \n",
    "                 tfidf_max_df_ngram_range=(1,3),\n",
    "                 tfidf_top_n=10,\n",
    "                 min_support=0.005, \n",
    "                 min_confidence=0.2, \n",
    "                 min_lift=3, \n",
    "                 min_length=3):\n",
    "        \n",
    "        if not self.revs:\n",
    "            self.preprocess()\n",
    "        \n",
    "        sentence_dict = []       \n",
    "        for r in self.revs:\n",
    "            sentence_dict.extend(r.sents()) \n",
    "        \n",
    "        \n",
    "        if len(self.revs) > 1:\n",
    "            # Normal review file with multiple reviews separated by title\n",
    "            top_n = list(self.get_tfidf_top_features([r.sents_str() for r in self.revs], \n",
    "                                                     tfidf_max_df=tfidf_max_df, \n",
    "                                                     tfidf_min_df=tfidf_min_df, \n",
    "                                                     tfidf_max_df_ngram_range=tfidf_max_df_ngram_range,\n",
    "                                                     n_top=tfidf_top_n))\n",
    "            # print(\"Found keywords \", len(top_n))\n",
    "            # print(top_n)\n",
    "        else:\n",
    "            # Some review files contain one single title (one review with many lines)\n",
    "            top_n = list(self.get_tfidf_top_features([' '.join(s) for s in sentence_dict], n_top=30))\n",
    "            \n",
    "        \n",
    "                       \n",
    "        # Applying Apriori algorithm to find more potential features:\n",
    "        \n",
    "        ar=None\n",
    "        if apr:\n",
    "            self.association_rules = apriori(sentence_dict, \n",
    "                                        min_support=min_support, \n",
    "                                        min_confidence=min_confidence, \n",
    "                                        min_lift=min_lift, \n",
    "                                        min_length=min_length)\n",
    "\n",
    "            ar = list(self.association_rules)\n",
    "            for f in ar:\n",
    "                top_n.extend(list(f.items))\n",
    "        \n",
    "        top_n = list(set(top_n))\n",
    "        \n",
    "        if prune:\n",
    "            top_n = self.feature_prunning(top_n)\n",
    "        \n",
    "        self._tag_sentences_with_features(top_n, ar)\n",
    "        \n",
    "        return top_n\n",
    "    \n",
    "    def opinions(self):\n",
    "        # Extracting opinion words (adjectives and adverbs)\n",
    "        # JJ adjective, JJR adj comparative, JJS adj superlative\n",
    "        # RB adverb, RBR comparative, RBS seperlative\n",
    "        for r in self.revs:\n",
    "            for s in r.review:               \n",
    "                for w in TextBlob(str(s)).tags:\n",
    "                    if (w[1][:2] == 'JJ' or\n",
    "                       w[1][:2] == 'RB'):\n",
    "                            # print(w[0])\n",
    "                            s.op.append(w[0])\n",
    "    \n",
    "    def sentiment(self):\n",
    "        # Detecting sentiment polarity in the sentences\n",
    "        # containing product features\n",
    "        for r in self.revs:\n",
    "            r.sentiment()\n",
    "                        \n",
    "    def gen_report(self):\n",
    "        \n",
    "        # Generate an product feature report\n",
    "        # Collect sentiment per feature from each review and\n",
    "        # store in tuple dict[feature] = (positive_count, negative_count)\n",
    "        \n",
    "        for r in self.revs:\n",
    "            for s in r.review:               \n",
    "                for feat, polarity in s.ft.items():\n",
    "                    self.report.setdefault(feat, (0,0))\n",
    "                    if polarity > 0:\n",
    "                        self.report[feat] = (self.report[feat][0]+1,\n",
    "                                             self.report[feat][1])\n",
    "                    elif polarity < 0:                \n",
    "                        self.report.setdefault(feat, (0,0))\n",
    "                        self.report[feat] = (self.report[feat][0],\n",
    "                                             self.report[feat][1]+1)\n",
    "            \n",
    "        return self.report\n",
    "    \n",
    "    def print_report(self, top_n=5):\n",
    "        if not self.report:\n",
    "            self.gen_report()\n",
    "            \n",
    "        sorted_dict = dict(sorted(self.report.items(), key=operator.itemgetter(1), reverse=True)[:top_n])\n",
    "            \n",
    "        print(\"\\nProduct: \", self.name)\n",
    "        for feat, score in sorted_dict.items():\n",
    "            print(\"\\t\\nFeature: \", feat)\n",
    "            print(\"\\t\\tPositive: \", sorted_dict[feat][0])\n",
    "            print(\"\\t\\tNegative: \", sorted_dict[feat][1])\n",
    "    \n",
    "    def extract_tagged_data(self):\n",
    "        self.test_report = {}\n",
    "        for r in self.NltkCorpus:\n",
    "            # print(\"\\n\")\n",
    "            for f in r.features():\n",
    "                feat = f[0] # name of feature\n",
    "                score_sign = f[1][0] #just the plus or minus sign\n",
    "                self.test_report.setdefault(feat, (0,0))\n",
    "                if score_sign == '+':\n",
    "                    self.test_report[feat] = (self.test_report[feat][0]+1,\n",
    "                                                 self.test_report[feat][1])\n",
    "                elif score_sign == '-':\n",
    "                    self.test_report[feat] = (self.test_report[feat][0],\n",
    "                                                 self.test_report[feat][1]+1)\n",
    "        #print(\"\\nProduct: \", self.name)\n",
    "        # for feat, score in test_report.items():\n",
    "        #    print(\"\\t\\nFeature: \", feat)\n",
    "        #    print(\"\\t\\tPositive: \", test_report[feat][0])\n",
    "        #    print(\"\\t\\tNegative: \", test_report[feat][1])\n",
    "        return self.test_report\n",
    "    \n",
    "    def fscore(self, tp, fn, fp):\n",
    "        recall = 0\n",
    "        prec = 0\n",
    "        fscore = 0\n",
    "        \n",
    "        if(tp+fn)>0:\n",
    "            recall = tp/(tp+fn) \n",
    "        \n",
    "        if(tp+fp)>0:\n",
    "            prec = tp/(tp+fp) \n",
    "            \n",
    "        if(recall+prec)>0:\n",
    "            fscore = 2*(recall*prec)/(recall+prec)\n",
    "        \n",
    "        return recall, prec, fscore\n",
    "    \n",
    "    def feat_evaluation(self, mute_output=False):\n",
    "        if not self.test_report:\n",
    "            self.extract_tagged_data()\n",
    "            \n",
    "        if not self.report:\n",
    "            self.gen_report()\n",
    "            \n",
    "        # Evaluation of feature extraction overall\n",
    "        # Look at features that were picked up by mining and\n",
    "        # those that were missed:\n",
    "        # cft = len(test_report.keys()) # total features in test data\n",
    "        # cfm = len(my_report.keys()) # total features in my model data\n",
    "        # cfmatch = 0 # count of matching features\n",
    "        f_tp = []\n",
    "        f_fp = []\n",
    "        f_fn = []\n",
    "        \n",
    "        for feat in self.report.keys():\n",
    "            if feat in self.test_report:\n",
    "                # cfmatch += 1\n",
    "                f_tp.append(feat)               \n",
    "            else:                \n",
    "                f_fp.append(feat)                \n",
    "                \n",
    "        for feat in self.test_report.keys():\n",
    "            if feat not in self.report:                \n",
    "                f_fn.append(feat)\n",
    "        \n",
    "        recall, prec, fscore = self.fscore(len(f_tp),\n",
    "                                           len(f_fn),\n",
    "                                           len(f_fp))\n",
    "        \n",
    "        results1 = [len(f_tp),len(f_fn),len(f_fp),recall,prec, fscore]\n",
    "    \n",
    "        if not mute_output:\n",
    "            print(\"Looking at all product features together:\")\n",
    "            print(\"|\\tTP\\t|\\tFN\\t|\\tFP\\t|\\tRecall\\t|\\tPrecision\\t|\\tF-score\\t|\")\n",
    "            print(\"|---|---|---|---|---|---|\")\n",
    "            print(\"|\\t{0}\\t|\\t{1}\\t|\\t{2}\\t|\\t{3:.2f}\\t|\\t{4:.2f}\\t|\\t{5:.2f}\\t|\".format(len(f_tp), \n",
    "                                                                                         len(f_fn), \n",
    "                                                                                         len(f_fp),\n",
    "                                                                                        recall,\n",
    "                                                                                        prec,\n",
    "                                                                                        fscore))\n",
    "        \n",
    "            print(\"\\nTP\")\n",
    "            print('%s' % ', '.join(map(str, f_tp)))\n",
    "\n",
    "            print(\"\\nFN\")\n",
    "            print('%s' % ', '.join(map(str, f_fn)))\n",
    "\n",
    "            print(\"\\nFP\")\n",
    "            print('%s' % ', '.join(map(str, f_fp)))\n",
    "\n",
    "        \n",
    "        # Calculate recall / precision and F1 score per sentence, review and product:\n",
    "        self.eval[\"tp\"] = 0 # true positive (labelled feature found in mined features)\n",
    "        self.eval[\"fn\"] = 0 # false negative (labelled feature not found in mined features)\n",
    "        self.eval[\"fp\"] = 0 # false positive, mined feature that is not present in labelled\n",
    "        self.eval[\"recall\"] = 0 \n",
    "        self.eval[\"prec\"] = 0 \n",
    "        self.eval[\"fscore\"] = 0 \n",
    "        for r in self.revs:\n",
    "            r.eval[\"tp\"] = 0 # true positive (labelled feature found in mined features)\n",
    "            r.eval[\"fn\"] = 0 # false negative (labelled feature not found in mined features)\n",
    "            r.eval[\"fp\"] = 0 # false positive, mined feature that is not present in labelled\n",
    "            r.eval[\"recall\"] = 0 \n",
    "            r.eval[\"prec\"] = 0 \n",
    "            r.eval[\"fscore\"] = 0 \n",
    "            for s in r.review: # iterate through each sentence\n",
    "                s.eval[\"tp\"] = 0 # true positive (labelled feature found in mined features)\n",
    "                s.eval[\"fn\"] = 0    # false negative (labelled feature not found in mined features)\n",
    "                s.eval[\"fp\"] = 0    # false positive, mined feature that is not present in labelled\n",
    "                s.eval[\"recall\"] = 0 \n",
    "                s.eval[\"prec\"] = 0 \n",
    "                s.eval[\"fscore\"] = 0 \n",
    "                for lf in s.test: # iterate through labelled features\n",
    "                    if lf[0] in s.ft.keys(): # comparing to mined features\n",
    "                        s.eval[\"tp\"] += 1\n",
    "                    else:                        \n",
    "                        s.eval[\"fn\"] += 1\n",
    "                for mf in s.ft.keys(): # iterate through labelled features\n",
    "                    found = False\n",
    "                    for lf in s.test:                        \n",
    "                        if mf == lf[0]:\n",
    "                            found = True\n",
    "                            break\n",
    "                    if not found:\n",
    "                        s.eval[\"fp\"] += 1                        \n",
    "                        \n",
    "                r.eval[\"tp\"] += s.eval[\"tp\"] # true positive (labelled feature found in mined features)\n",
    "                r.eval[\"fn\"] += s.eval[\"fn\"] # false negative (labelled feature not found in mined features)\n",
    "                r.eval[\"fp\"] += s.eval[\"fp\"] # false positive, mined feature that is not present in labelled\n",
    "                \n",
    "                # Recall / precision / F1 score per sentence:\n",
    "                s.eval[\"recall\"], s.eval[\"prec\"], s.eval[\"fscore\"] = self.fscore(s.eval[\"tp\"],\n",
    "                                                                               s.eval[\"fn\"],\n",
    "                                                                               s.eval[\"fp\"])\n",
    "                \n",
    "            self.eval[\"tp\"] += r.eval[\"tp\"] # true positive (labelled feature found in mined features)\n",
    "            self.eval[\"fn\"] += r.eval[\"fn\"] # false negative (labelled feature not found in mined features)\n",
    "            self.eval[\"fp\"] += r.eval[\"fp\"] # false positive, mined feature that is not present in labelled\n",
    "                \n",
    "            # Recall / precision / F1 score per review:\n",
    "            r.eval[\"recall\"], r.eval[\"prec\"], r.eval[\"fscore\"] = self.fscore(r.eval[\"tp\"],\n",
    "                                                                           r.eval[\"fn\"],\n",
    "                                                                           r.eval[\"fp\"])\n",
    "            \n",
    "        # Recall / precision / F1 score per product:\n",
    "        self.eval[\"recall\"], self.eval[\"prec\"], self.eval[\"fscore\"] = self.fscore(self.eval[\"tp\"],\n",
    "                                                                                   self.eval[\"fn\"],\n",
    "                                                                                   self.eval[\"fp\"])\n",
    "        \n",
    "        results2 = [self.eval[\"tp\"],\n",
    "                    self.eval[\"fn\"],\n",
    "                    self.eval[\"fp\"],\n",
    "                    self.eval[\"recall\"],\n",
    "                    self.eval[\"prec\"],\n",
    "                    self.eval[\"fscore\"]]\n",
    "        if not mute_output:\n",
    "            print(\"\\n\\nLooking at product features per individual sentence:\")\n",
    "            print(\"|\\tTP\\t|\\tFN\\t|\\tFP\\t|\\tRecall\\t|\\tPrec\\t|\\tF score\\t|\")\n",
    "            print(\"|\\t{0}\\t|\\t{1}\\t|\\t{2}\\t|\\t{3:.2f}\\t|\\t{4:.2f}\\t|\\t{5:.2f}\\t|\"\n",
    "                  .format(self.eval[\"tp\"],\n",
    "                        self.eval[\"fn\"],\n",
    "                        self.eval[\"fp\"],\n",
    "                        self.eval[\"recall\"],\n",
    "                        self.eval[\"prec\"],\n",
    "                        self.eval[\"fscore\"]))\n",
    "\n",
    "        return results1, results2\n",
    "        \n",
    "    def sent_evaluation(self, mute_output=False):   \n",
    "        \n",
    "        if not self.test_report:\n",
    "            self.extract_tagged_data()\n",
    "            \n",
    "        if not self.report:\n",
    "            self.gen_report()\n",
    "            \n",
    "        # First collect features that were correctly mined\n",
    "        f_tp = []        \n",
    "        for feat in self.report.keys():\n",
    "            if feat in self.test_report:\n",
    "                f_tp.append(feat)\n",
    "\n",
    "        # Calculate recall / precision and F1 score per sentence, review and product\n",
    "        # on those sentences that contain features that were correctly mined:\n",
    "        self.eval[\"stp\"] = 0 # true positive (positive feature labelled positive)\n",
    "        self.eval[\"sfn\"] = 0 # false negative (positive feature not labelled positive)\n",
    "        self.eval[\"sfp\"] = 0 # false positive (negative feature labelled positive)\n",
    "        self.eval[\"srecall\"] = 0 \n",
    "        self.eval[\"sprec\"] = 0 \n",
    "        self.eval[\"sfscore\"] = 0 \n",
    "        for r in self.revs:\n",
    "            r.eval[\"stp\"] = 0 # true positive (positive feature labelled positive)\n",
    "            r.eval[\"sfn\"] = 0 # false negative (positive feature not labelled positive)\n",
    "            r.eval[\"sfp\"] = 0 # false positive (negative feature labelled positive)\n",
    "            r.eval[\"srecall\"] = 0 \n",
    "            r.eval[\"sprec\"] = 0 \n",
    "            r.eval[\"sfscore\"] = 0 \n",
    "            for s in r.review: # iterate through each sentence\n",
    "                s.eval[\"stp\"] = 0 # true positive (positive feature labelled positive)\n",
    "                s.eval[\"sfn\"] = 0    # false negative (positive feature not labelled positive)\n",
    "                s.eval[\"sfp\"] = 0    # false positive (negative feature labelled positive)\n",
    "                s.eval[\"srecall\"] = 0 \n",
    "                s.eval[\"sprec\"] = 0 \n",
    "                s.eval[\"sfscore\"] = 0 \n",
    "                for lf in s.test: # iterate through labelled features\n",
    "                    if lf[0] in s.ft: # comparing to mined features\n",
    "                        if sign(int(lf[1])) == s.ft[lf[0]]:\n",
    "                            s.eval[\"stp\"] += 1\n",
    "                            # print(\"TP {}:{}=={}:{}\".format(lf[0],sign(int(lf[1])),lf[0], s.ft[lf[0]]))\n",
    "                        elif sign(int(lf[1])) == 1.0:\n",
    "                            s.eval[\"sfn\"] += 1\n",
    "                            # print(\"Falsely negative:\")\n",
    "                            # print(s)\n",
    "                        else:\n",
    "                            s.eval[\"sfp\"] += 1\n",
    "                            # print(\"Falsely positive:\")\n",
    "                            # print(s)\n",
    "                        \n",
    "                r.eval[\"stp\"] += s.eval[\"stp\"] # true positive (positive feature labelled positive)\n",
    "                r.eval[\"sfn\"] += s.eval[\"sfn\"] # false negative (positive feature not labelled positive)\n",
    "                r.eval[\"sfp\"] += s.eval[\"sfp\"] # false positive (negative feature labelled positive)\n",
    "                \n",
    "                # Recall / precision / F1 score per sentence:\n",
    "                s.eval[\"srecall\"], s.eval[\"sprec\"], s.eval[\"sfscore\"] = self.fscore(s.eval[\"stp\"],\n",
    "                                                                               s.eval[\"sfn\"],\n",
    "                                                                               s.eval[\"sfp\"])\n",
    "                \n",
    "            self.eval[\"stp\"] += r.eval[\"stp\"] # true positive (positive feature labelled positive)\n",
    "            self.eval[\"sfn\"] += r.eval[\"sfn\"] # false negative (positive feature not labelled positive)\n",
    "            self.eval[\"sfp\"] += r.eval[\"sfp\"] # false positive (negative feature labelled positive)\n",
    "                \n",
    "            # Recall / precision / F1 score per review:\n",
    "            r.eval[\"srecall\"], r.eval[\"sprec\"], r.eval[\"sfscore\"] = self.fscore(r.eval[\"stp\"],\n",
    "                                                                           r.eval[\"sfn\"],\n",
    "                                                                           r.eval[\"sfp\"])\n",
    "            \n",
    "        # Recall / precision / F1 score per product:\n",
    "        self.eval[\"srecall\"], self.eval[\"sprec\"], self.eval[\"sfscore\"] = self.fscore(self.eval[\"stp\"],\n",
    "                                                                                   self.eval[\"sfn\"],\n",
    "                                                                                   self.eval[\"sfp\"])\n",
    "        results = [self.eval[\"stp\"],\n",
    "                    self.eval[\"sfn\"],\n",
    "                    self.eval[\"sfp\"],\n",
    "                    self.eval[\"srecall\"],\n",
    "                    self.eval[\"sprec\"],\n",
    "                    self.eval[\"sfscore\"]]\n",
    "        if not mute_output:\n",
    "            print(\"\\n\\nLooking at sentiment evaluation per individual sentence:\")\n",
    "            print(\"|\\tTP\\t|\\tFN\\t|\\tFP\\t|\\tRecall\\t|\\tPrec\\t|\\tF score\\t|\")\n",
    "            print(\"|\\t{0}\\t|\\t{1}\\t|\\t{2}\\t|\\t{3:.2f}\\t|\\t{4:.2f}\\t|\\t{5:.2f}\\t|\"\n",
    "                  .format(self.eval[\"stp\"],\n",
    "                        self.eval[\"sfn\"],\n",
    "                        self.eval[\"sfp\"],\n",
    "                        self.eval[\"srecall\"],\n",
    "                        self.eval[\"sprec\"],\n",
    "                        self.eval[\"sfscore\"]))\n",
    "        return results\n",
    "    \n",
    "    def d(w1, w2, words):\n",
    "        if w1 in words and w2 in words:\n",
    "            w1_indexes = [index for index, value in enumerate(words) if value == w1]    \n",
    "            w2_indexes = [index for index, value in enumerate(words) if value == w2]    \n",
    "            distances = [abs(item[0] - item[1]) for item in itertools.product(w1_indexes, w2_indexes)]\n",
    "            return {'min': min(distances), 'avg': sum(distances)/float(len(distances))}\n",
    "    \n",
    "    def compactness_prunning(self, multiple_word_features):\n",
    "        exclude = []\n",
    "        for (mw, parts) in multiple_word_features:\n",
    "            compact_count = 0\n",
    "            if len(parts) == 2:\n",
    "                for r in self.revs:\n",
    "                    for s in r.review:\n",
    "                        if mw in s.ft:\n",
    "                            distance = d(parts[0],parts[1],s.raw)\n",
    "                            if distance and distance[\"min\"] <= 3:\n",
    "                                # print(\"{} is compact in {}\".format(mw,s.raw))\n",
    "                                compact_count+=1\n",
    "                    if compact_count >= 2:\n",
    "                        break\n",
    "            if compact_count < 2:\n",
    "                exclude.append(mw)\n",
    "        return exclude            \n",
    "    \n",
    "    def feature_prunning(self, features):\n",
    "        hierarchy = {}\n",
    "        multiword = []\n",
    "        exclude = []\n",
    "        \n",
    "        # features = self.report.keys()\n",
    "        \n",
    "        count_start = len(features)\n",
    "\n",
    "        for f in features:\n",
    "            parts = f.split(' ')\n",
    "            if len(parts) == 1:\n",
    "                hierarchy[f]=[]\n",
    "            else:\n",
    "                # check if words in the multi-word feature repeat\n",
    "                if not len(set(parts)) == len(list(parts)):\n",
    "                    #print(\"Exclude (repetition): \", f)\n",
    "                    exclude.append(f)\n",
    "                else:\n",
    "                    multiword.append((f,parts))\n",
    "                    \n",
    "        exclude.extend(self.compactness_prunning(multiword))\n",
    "\n",
    "        for mw, parts in multiword:\n",
    "            for p in parts:\n",
    "                if p in hierarchy.keys():\n",
    "                    # multiword feature is a narrower category of feature p\n",
    "                    hierarchy[p].append(mw)\n",
    "\n",
    "        document_presence = {}\n",
    "        for w, more_specific in hierarchy.items():\n",
    "            for mw in more_specific:\n",
    "                both = 0\n",
    "                general = 0\n",
    "                for r in self.revs:\n",
    "                    if mw in r.sents_str():\n",
    "                        both += 1\n",
    "                    elif w in r.sents_str():\n",
    "                        general += 1\n",
    "                # print(\"{} vs {}, both {} general {} ratio {}\".format(w,mw,both,general,(general+both)/both))\n",
    "                if both > 0 and general/both == 1:\n",
    "                    # print(\"Exclude\".format(w))\n",
    "                    exclude.append(w)\n",
    "        \n",
    "        result = [f for f in features if f not in exclude]\n",
    "        count_end = len(result)\n",
    "        \n",
    "        print(\"Pruned {} out of {} features\".format(count_start-count_end,count_start))\n",
    "\n",
    "        return result\n",
    "\n",
    "\n",
    "    def _tag_sentences_with_features(self, features, ar=None):\n",
    "        for r in self.revs:\n",
    "            for s in r.review:\n",
    "                found = False\n",
    "                for word in features:\n",
    "                    # print(\"Check if {} in {}\".format(word, s.pp))\n",
    "                    if word in s.pp:                        \n",
    "                        # print(\"Found feature {} in {}\".format(word, s.pp))\n",
    "                        s.ft[word]=0\n",
    "                        \n",
    "                # print(\"Checking review for features\") \n",
    "                if ar:\n",
    "                    for f in ar:\n",
    "                        feat = list(f.items)  \n",
    "                        # print(feat)\n",
    "\n",
    "                        found = False\n",
    "                        for word in feat:\n",
    "                            # print(\"Check if {} in {}\".format(e, s))\n",
    "                            found = False\n",
    "                            for np in s.pp:\n",
    "                                if word == np or word in np:\n",
    "                                    # print(\"Found feature {} in {}\".format(e, np))\n",
    "                                    found = True\n",
    "                                    break\n",
    "                            if not found:\n",
    "                                break                \n",
    "                        if(found):                        \n",
    "                            featstr = feat[1]+' '+feat[0]\n",
    "                            # print(\"Found {} in {}\".format(feat[::-1], s))\n",
    "                            # s.ft.append(feat[::-1])\n",
    "                            s.ft[featstr]=0\n",
    "        \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process one product and generate the feature report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed 45 reviews in 0.55 seconds (spelling correction=False, stemming=False)\n",
      "Looking at all product features together:\n",
      "|\tTP\t|\tFN\t|\tFP\t|\tRecall\t|\tPrecision\t|\tF-score\t|\n",
      "|---|---|---|---|---|---|\n",
      "|\t25\t|\t80\t|\t61\t|\t0.24\t|\t0.29\t|\t0.26\t|\n",
      "\n",
      "TP\n",
      "canon, camera, picture, quality, flash, use, software, control, lens, viewfinder, speed, image, lcd, design, photo, display, focus, zoom, battery, shoot, price, color, feel, compactflash, performance\n",
      "\n",
      "FN\n",
      "canon powershot g3, picture quality, feature, option, dial, function, auto setting, canon g3, photo quality, darn diopter adjustment dial, exposure control, metering option, spot metering, 4mp, size, weight, optical zoom, digital zoom, lens cap, menu, button, lense, auto mode, canera, print, manual mode, four megapixel, product, night mode, lens cover, zooming lever, white balance, grain, flash photo, noise, g3, lag time, depth, external flash hot shoe, raw image, battery life, manual function, service, automode, raw format, shape, light auto correction, white offset, low light focus, unresponsiveness, delay, 4mp camera, body, casing, look, finish, tiff format, lag, import, manual, stitch picture, memory card, made, lever, strap, learning, image quality, macro, 4mp resolution, distortion, shot, learning curve, remote, hot shoe flash, battery charging system, highlight, off button, download, optic, digital camera\n",
      "\n",
      "FP\n",
      "fact, week, way, pictures, work, cameras, card, features, flexibility, ease, months, megapixel, images, research, reviews, review, sample, online, resolution, settings, mode, photos, shutter, time, photography, screen, people, exposure, auto, range, market, results, film, point, sort, cap, view, years, powershot, pics, store, bit, life, finder, amazon, batteries, shots, priority, lot, days, light, printer, buy, effect, processing, nikon, pros, com, adjustments, home, barrel\n",
      "\n",
      "\n",
      "Looking at product features per individual sentence:\n",
      "|\tTP\t|\tFN\t|\tFP\t|\tRecall\t|\tPrec\t|\tF score\t|\n",
      "|\t90\t|\t195\t|\t962\t|\t0.32\t|\t0.09\t|\t0.13\t|\n",
      "\n",
      "Product:  Canon_G3.txt\n",
      "\t\n",
      "Feature:  camera\n",
      "\t\tPositive:  108\n",
      "\t\tNegative:  24\n",
      "\t\n",
      "Feature:  quality\n",
      "\t\tPositive:  30\n",
      "\t\tNegative:  2\n",
      "\t\n",
      "Feature:  pictures\n",
      "\t\tPositive:  29\n",
      "\t\tNegative:  2\n",
      "\t\n",
      "Feature:  canon\n",
      "\t\tPositive:  25\n",
      "\t\tNegative:  8\n",
      "\t\n",
      "Feature:  features\n",
      "\t\tPositive:  23\n",
      "\t\tNegative:  2\n"
     ]
    }
   ],
   "source": [
    "c = PReviews(product_reviews_1, 'Canon_G3.txt')\n",
    "c.preprocess(chunking=False, lemmatization=False)\n",
    "c.features(apr = False,\n",
    "           prune=False,\n",
    "                 tfidf_max_df=0.80, \n",
    "                 tfidf_min_df=0.03, \n",
    "                 tfidf_max_df_ngram_range=(1,3),\n",
    "                 tfidf_top_n=100,\n",
    "                 min_support=0.004, \n",
    "                 min_confidence=0.2, \n",
    "                 min_lift=3, \n",
    "                 min_length=3)\n",
    "c.opinions()\n",
    "c.sentiment()\n",
    "c.feat_evaluation(mute_output=False)\n",
    "c.sent_evaluation(mute_output=True)\n",
    "c.print_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating results on multiple products / markdown generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed 99 reviews in 0.74 seconds (spelling correction=False, stemming=False)\n",
      "Pruned 29 out of 134 features\n",
      "Preprocessed 45 reviews in 0.73 seconds (spelling correction=False, stemming=False)\n",
      "Pruned 78 out of 240 features\n",
      "Preprocessed 95 reviews in 2.01 seconds (spelling correction=False, stemming=False)\n",
      "Pruned 14 out of 113 features\n",
      "Preprocessed 34 reviews in 0.44 seconds (spelling correction=False, stemming=False)\n",
      "Pruned 44 out of 159 features\n",
      "Preprocessed 40 reviews in 0.62 seconds (spelling correction=False, stemming=False)\n",
      "Pruned 45 out of 181 features\n",
      "Looking at features per product:\n",
      "|\tName\t|\tTP\t|\tFN\t|\tFP\t|\tRecall\t|\tPrecision\t|\tF-score\t|\n",
      "|:---|:---:|:---:|:---:|:---:|:---:|:---:|\n",
      "|\tApex_AD2600_Progressive_scan_DVD player.txt\t|\t43\t|\t72\t|\t179\t|\t0.37\t|\t0.19\t|\t0.26\t|\n",
      "|\tCanon_G3.txt\t|\t40\t|\t65\t|\t550\t|\t0.38\t|\t0.07\t|\t0.12\t|\n",
      "|\tCreative_Labs_Nomad_Jukebox_Zen_Xtra_40GB.txt\t|\t47\t|\t141\t|\t131\t|\t0.25\t|\t0.26\t|\t0.26\t|\n",
      "|\tNikon_coolpix_4300.txt\t|\t24\t|\t51\t|\t267\t|\t0.32\t|\t0.08\t|\t0.13\t|\n",
      "|\tNokia_6610.txt\t|\t45\t|\t66\t|\t323\t|\t0.41\t|\t0.12\t|\t0.19\t|\n",
      "|\tAverage values\t|\t**39.80**\t|\t**79.00**\t|\t**290.00**\t|\t**0.35**\t|\t**0.15**\t|\t**0.19**\t|\n",
      "Looking at features per sentence:\n",
      "|\tName\t|\tTP\t|\tFN\t|\tFP\t|\tRecall\t|\tPrecision\t|\tF-score\t|\n",
      "|:---|:---:|:---:|:---:|:---:|:---:|:---:|\n",
      "|\tApex_AD2600_Progressive_scan_DVD player.txt\t|\t196\t|\t234\t|\t2158\t|\t0.46\t|\t0.08\t|\t0.14\t|\n",
      "|\tCanon_G3.txt\t|\t150\t|\t135\t|\t2597\t|\t0.53\t|\t0.05\t|\t0.10\t|\n",
      "|\tCreative_Labs_Nomad_Jukebox_Zen_Xtra_40GB.txt\t|\t419\t|\t426\t|\t4059\t|\t0.50\t|\t0.09\t|\t0.16\t|\n",
      "|\tNikon_coolpix_4300.txt\t|\t101\t|\t102\t|\t1211\t|\t0.50\t|\t0.08\t|\t0.13\t|\n",
      "|\tNokia_6610.txt\t|\t174\t|\t164\t|\t1580\t|\t0.51\t|\t0.10\t|\t0.17\t|\n",
      "|\tAverage values\t|\t**208.00**\t|\t**212.20**\t|\t**2321.00**\t|\t**0.50**\t|\t**0.08**\t|\t**0.14**\t|\n",
      "Looking at sentiment analysis:\n",
      "|\tName\t|\tTP\t|\tFN\t|\tFP\t|\tRecall\t|\tPrecision\t|\tF-score\t|\n",
      "|:---|:---:|:---:|:---:|:---:|:---:|:---:|\n",
      "|\tApex_AD2600_Progressive_scan_DVD player.txt\t|\t105\t|\t15\t|\t76\t|\t0.88\t|\t0.58\t|\t0.70\t|\n",
      "|\tCanon_G3.txt\t|\t117\t|\t16\t|\t17\t|\t0.88\t|\t0.87\t|\t0.88\t|\n",
      "|\tCreative_Labs_Nomad_Jukebox_Zen_Xtra_40GB.txt\t|\t283\t|\t43\t|\t93\t|\t0.87\t|\t0.75\t|\t0.81\t|\n",
      "|\tNikon_coolpix_4300.txt\t|\t79\t|\t14\t|\t8\t|\t0.85\t|\t0.91\t|\t0.88\t|\n",
      "|\tNokia_6610.txt\t|\t127\t|\t23\t|\t24\t|\t0.85\t|\t0.84\t|\t0.84\t|\n",
      "|\tAverage values\t|\t**142.20**\t|\t**22.20**\t|\t**43.60**\t|\t**0.86**\t|\t**0.79**\t|\t**0.82**\t|\n"
     ]
    }
   ],
   "source": [
    "# This is a bit messy and is intended to output evaluation results of the opinion miner \n",
    "# for all the products in both corpora formatted as markdown.\n",
    "\n",
    "results1 = {}\n",
    "results2 = {}\n",
    "results3 = {}\n",
    "sum1=[0.0,0.0,0.0,0.0,0.0,0.0]\n",
    "sum2=[0.0,0.0,0.0,0.0,0.0,0.0]\n",
    "sum3=[0.0,0.0,0.0,0.0,0.0,0.0]\n",
    "\n",
    "count = 0\n",
    "for corpus in [product_reviews_1, product_reviews_2]:\n",
    "    for product in corpus.fileids():\n",
    "        if count < 5:            \n",
    "            if product not in ['README.txt','ipod.txt', 'norton.txt']:            \n",
    "                c = PReviews(corpus, product)\n",
    "                c.preprocess(chunking=True, lemmatization=True,spelling = False, stemming = False)\n",
    "                c.features(apr = True,\n",
    "               prune=True,\n",
    "                     tfidf_max_df=0.80, \n",
    "                     tfidf_min_df=0.03, \n",
    "                     tfidf_max_df_ngram_range=(1,3),\n",
    "                     tfidf_top_n=100,\n",
    "                     min_support=0.003, \n",
    "                     min_confidence=0.2, \n",
    "                     min_lift=3, \n",
    "                     min_length=3)\n",
    "                c.opinions()\n",
    "                c.sentiment()\n",
    "                r1,r2 = c.feat_evaluation(mute_output=True)\n",
    "                r3 = c.sent_evaluation(mute_output=True)\n",
    "                results1[product]=r1\n",
    "                results2[product]=r2\n",
    "                results3[product]=r3\n",
    "                sum1 = [x + y for x, y in zip(sum1, r1)]            \n",
    "                sum2 = [x + y for x, y in zip(sum2, r2)]\n",
    "                sum3 = [x + y for x, y in zip(sum3, r3)]\n",
    "                count+=1\n",
    "            \n",
    "sum1=[x / count for x in sum1]\n",
    "sum2=[x / count for x in sum2]\n",
    "sum3=[x / count for x in sum3]\n",
    "\n",
    "print(\"Looking at features per product:\")\n",
    "print(\"|\\tName\\t|\\tTP\\t|\\tFN\\t|\\tFP\\t|\\tRecall\\t|\\tPrecision\\t|\\tF-score\\t|\")\n",
    "print(\"|:---|:---:|:---:|:---:|:---:|:---:|:---:|\")\n",
    "for product, r in results1.items():\n",
    "    print(\"|\\t{6}\\t|\\t{0}\\t|\\t{1}\\t|\\t{2}\\t|\\t{3:.2f}\\t|\\t{4:.2f}\\t|\\t{5:.2f}\\t|\".format(r[0], \n",
    "                                                                                 r[1], \n",
    "                                                                                 r[2],\n",
    "                                                                                r[3],\n",
    "                                                                                r[4],\n",
    "                                                                                r[5],\n",
    "                                                                                        product))\n",
    "print(\"|\\t{6}\\t|\\t**{0:.2f}**\\t|\\t**{1:.2f}**\\t|\\t**{2:.2f}**\\t|\\t**{3:.2f}**\\t|\\t**{4:.2f}**\\t|\\t**{5:.2f}**\\t|\".format(sum1[0], \n",
    "                                                                             sum1[1], \n",
    "                                                                             sum1[2],\n",
    "                                                                            sum1[3],\n",
    "                                                                            sum1[4],\n",
    "                                                                            sum1[5],\n",
    "                                                                                    \"Average values\"))\n",
    "    \n",
    "print(\"Looking at features per sentence:\")\n",
    "print(\"|\\tName\\t|\\tTP\\t|\\tFN\\t|\\tFP\\t|\\tRecall\\t|\\tPrecision\\t|\\tF-score\\t|\")\n",
    "print(\"|:---|:---:|:---:|:---:|:---:|:---:|:---:|\")\n",
    "for product, r in results2.items():\n",
    "    print(\"|\\t{6}\\t|\\t{0}\\t|\\t{1}\\t|\\t{2}\\t|\\t{3:.2f}\\t|\\t{4:.2f}\\t|\\t{5:.2f}\\t|\".format(r[0], \n",
    "                                                                                 r[1], \n",
    "                                                                                 r[2],\n",
    "                                                                                r[3],\n",
    "                                                                                r[4],\n",
    "                                                                                r[5],\n",
    "                                                                                        product))\n",
    "print(\"|\\t{6}\\t|\\t**{0:.2f}**\\t|\\t**{1:.2f}**\\t|\\t**{2:.2f}**\\t|\\t**{3:.2f}**\\t|\\t**{4:.2f}**\\t|\\t**{5:.2f}**\\t|\".format(sum2[0], \n",
    "                                                                             sum2[1], \n",
    "                                                                             sum2[2],\n",
    "                                                                            sum2[3],\n",
    "                                                                            sum2[4],\n",
    "                                                                            sum2[5],\n",
    "                                                                                    \"Average values\"))\n",
    "    \n",
    "print(\"Looking at sentiment analysis:\")\n",
    "print(\"|\\tName\\t|\\tTP\\t|\\tFN\\t|\\tFP\\t|\\tRecall\\t|\\tPrecision\\t|\\tF-score\\t|\")\n",
    "print(\"|:---|:---:|:---:|:---:|:---:|:---:|:---:|\")\n",
    "for product, r in results3.items():\n",
    "    print(\"|\\t{6}\\t|\\t{0}\\t|\\t{1}\\t|\\t{2}\\t|\\t{3:.2f}\\t|\\t{4:.2f}\\t|\\t{5:.2f}\\t|\".format(r[0], \n",
    "                                                                                 r[1], \n",
    "                                                                                 r[2],\n",
    "                                                                                r[3],\n",
    "                                                                                r[4],\n",
    "                                                                                r[5],\n",
    "                                                                                        product))\n",
    "print(\"|\\t{6}\\t|\\t**{0:.2f}**\\t|\\t**{1:.2f}**\\t|\\t**{2:.2f}**\\t|\\t**{3:.2f}**\\t|\\t**{4:.2f}**\\t|\\t**{5:.2f}**\\t|\".format(sum3[0], \n",
    "                                                                             sum3[1], \n",
    "                                                                             sum3[2],\n",
    "                                                                            sum3[3],\n",
    "                                                                            sum3[4],\n",
    "                                                                            sum3[5],\n",
    "                                                                                    \"Average values\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manually parsing the corpora\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_tagged_reviews(path):\n",
    "    with open(path, 'r') as f:\n",
    "        reviews = []\n",
    "        \n",
    "        title = \"\"\n",
    "        text = []\n",
    "        for line in f.readlines():\n",
    "            if line.startswith(\"*\"): \n",
    "                # skip comment                \n",
    "                continue\n",
    "            elif line.startswith(\"[t]\"):                 \n",
    "                # title of new review\n",
    "                if text: # but title can be empty                    \n",
    "                    reviews.append(text)                \n",
    "                text = [] # reset last review\n",
    "                features = \"\" # reset last feature\n",
    "                title = line[3:]\n",
    "                # print(\"Title:\", title)                \n",
    "            elif line.startswith(\"##\"): # sentence\n",
    "                text.append(line[2:])\n",
    "            elif not line.startswith(\"##\") and \"##\" in line: #feature\n",
    "                s = line.split(\"##\")\n",
    "                features = s[0]\n",
    "                text.append(s[1])\n",
    "        # append the last review\n",
    "        reviews.append(text)\n",
    "    return reviews\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
